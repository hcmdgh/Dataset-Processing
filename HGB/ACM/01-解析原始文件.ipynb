{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10942it [00:02, 5226.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3025, 1902), (5959, 1902), (56, 1902), 1902)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv \n",
    "import os \n",
    "import json \n",
    "import numpy as np \n",
    "import traceback \n",
    "from tqdm import tqdm \n",
    "\n",
    "with open(os.path.expanduser('~/dataset/HGB/raw/ACM/node.dat'), 'r', encoding='utf-8') as fp:\n",
    "    reader = csv.DictReader(fp, fieldnames=['nid', 'name', 'node_type', 'feat'], delimiter='\\t') \n",
    "\n",
    "    author_feat_list = [] \n",
    "    paper_feat_list = [] \n",
    "    subject_feat_list = [] \n",
    "    term_feat_list = [] \n",
    "    \n",
    "    nid_map: dict[int, tuple[str, int]] = dict() \n",
    "\n",
    "    for row in tqdm(reader):\n",
    "        nid = int(row['nid']) \n",
    "        name = row['name'].strip() \n",
    "        ntype = int(row['node_type']) \n",
    "\n",
    "        try:\n",
    "            feat_str = row['feat'].strip() \n",
    "            feat = np.array(json.loads(f\"[{feat_str}]\"), dtype=np.float32)  \n",
    "        except Exception:\n",
    "            feat = None  \n",
    "            \n",
    "        if ntype == 0: \n",
    "            nid_map[nid] = ('paper', len(paper_feat_list)) \n",
    "            paper_feat_list.append(feat)\n",
    "        elif ntype == 1: \n",
    "            nid_map[nid] = ('author', len(author_feat_list)) \n",
    "            author_feat_list.append(feat)\n",
    "        elif ntype == 2: \n",
    "            nid_map[nid] = ('subject', len(subject_feat_list)) \n",
    "            subject_feat_list.append(feat) \n",
    "        elif ntype == 3: \n",
    "            nid_map[nid] = ('term', len(term_feat_list)) \n",
    "            term_feat_list.append(feat)\n",
    "        else:\n",
    "            raise AssertionError \n",
    "            \n",
    "author_feat = np.stack(author_feat_list) \n",
    "paper_feat = np.stack(paper_feat_list) \n",
    "subject_feat = np.stack(subject_feat_list) \n",
    "assert all(x is None for x in term_feat_list) \n",
    "    \n",
    "paper_feat.shape, \\\n",
    "author_feat.shape, \\\n",
    "subject_feat.shape, \\\n",
    "len(term_feat_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "547872it [00:01, 336784.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2, 5343),\n",
       " (2, 5343),\n",
       " (2, 9949),\n",
       " (2, 9949),\n",
       " (2, 3025),\n",
       " (2, 3025),\n",
       " (2, 255619),\n",
       " (2, 255619))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.expanduser('~/dataset/HGB/raw/ACM/link.dat'), 'r', encoding='utf-8') as fp:\n",
    "    reader = csv.DictReader(fp, fieldnames=['src_nid', 'dest_nid', 'etype', 'score'], delimiter='\\t') \n",
    "    \n",
    "    paper_paper_edge_list = []\n",
    "    rev_paper_paper_edge_list = []\n",
    "    paper_author_edge_list = []\n",
    "    author_paper_edge_list = []\n",
    "    paper_subject_edge_list = [] \n",
    "    subject_paper_edge_list = [] \n",
    "    paper_term_edge_list = [] \n",
    "    term_paper_edge_list = [] \n",
    "    \n",
    "    for row in tqdm(reader):\n",
    "        src_nid = int(row['src_nid'])\n",
    "        dest_nid = int(row['dest_nid']) \n",
    "        etype = int(row['etype'])\n",
    "        score = float(row['score']) \n",
    "        assert score == 1. \n",
    "        \n",
    "        if etype == 0:\n",
    "            assert nid_map[src_nid][0] == 'paper' and nid_map[dest_nid][0] == 'paper'\n",
    "            paper_paper_edge_list.append((nid_map[src_nid][1], nid_map[dest_nid][1])) \n",
    "        elif etype == 1:\n",
    "            assert nid_map[src_nid][0] == 'paper' and nid_map[dest_nid][0] == 'paper'\n",
    "            rev_paper_paper_edge_list.append((nid_map[src_nid][1], nid_map[dest_nid][1])) \n",
    "        elif etype == 2:\n",
    "            assert nid_map[src_nid][0] == 'paper' and nid_map[dest_nid][0] == 'author'\n",
    "            paper_author_edge_list.append((nid_map[src_nid][1], nid_map[dest_nid][1])) \n",
    "        elif etype == 3:\n",
    "            assert nid_map[src_nid][0] == 'author' and nid_map[dest_nid][0] == 'paper'\n",
    "            author_paper_edge_list.append((nid_map[src_nid][1], nid_map[dest_nid][1])) \n",
    "        elif etype == 4:\n",
    "            assert nid_map[src_nid][0] == 'paper' and nid_map[dest_nid][0] == 'subject'\n",
    "            paper_subject_edge_list.append((nid_map[src_nid][1], nid_map[dest_nid][1])) \n",
    "        elif etype == 5:\n",
    "            assert nid_map[src_nid][0] == 'subject' and nid_map[dest_nid][0] == 'paper'\n",
    "            subject_paper_edge_list.append((nid_map[src_nid][1], nid_map[dest_nid][1])) \n",
    "        elif etype == 6:\n",
    "            assert nid_map[src_nid][0] == 'paper' and nid_map[dest_nid][0] == 'term'\n",
    "            paper_term_edge_list.append((nid_map[src_nid][1], nid_map[dest_nid][1])) \n",
    "        elif etype == 7:\n",
    "            assert nid_map[src_nid][0] == 'term' and nid_map[dest_nid][0] == 'paper'\n",
    "            term_paper_edge_list.append((nid_map[src_nid][1], nid_map[dest_nid][1])) \n",
    "        else:\n",
    "            raise AssertionError \n",
    "\n",
    "paper_paper_edge_index = np.array(paper_paper_edge_list, dtype=np.int64).T \n",
    "rev_paper_paper_edge_index = np.array(rev_paper_paper_edge_list, dtype=np.int64).T \n",
    "paper_author_edge_index = np.array(paper_author_edge_list, dtype=np.int64).T \n",
    "author_paper_edge_index = np.array(author_paper_edge_list, dtype=np.int64).T \n",
    "paper_subject_edge_index = np.array(paper_subject_edge_list, dtype=np.int64).T \n",
    "subject_paper_edge_index = np.array(subject_paper_edge_list, dtype=np.int64).T \n",
    "paper_term_edge_index = np.array(paper_term_edge_list, dtype=np.int64).T \n",
    "term_paper_edge_index = np.array(term_paper_edge_list, dtype=np.int64).T \n",
    "\n",
    "paper_paper_edge_index.shape, \\\n",
    "rev_paper_paper_edge_index.shape, \\\n",
    "paper_author_edge_index.shape, \\\n",
    "author_paper_edge_index.shape, \\\n",
    "paper_subject_edge_index.shape, \\\n",
    "subject_paper_edge_index.shape, \\\n",
    "paper_term_edge_index.shape, \\\n",
    "term_paper_edge_index.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "907it [00:00, 156032.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3025,), 907, 907)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.expanduser('~/dataset/HGB/raw/ACM/label.dat'), 'r', encoding='utf-8') as fp:\n",
    "    reader = csv.DictReader(fp, fieldnames=['paper_nid', 'paper_name', 'node_type', 'paper_label'], delimiter='\\t') \n",
    "    \n",
    "    paper_label_arr = np.full([len(paper_feat)], fill_value=-1, dtype=np.int64)   \n",
    "    paper_train_mask = np.zeros(len(paper_feat), dtype=bool) \n",
    "    \n",
    "    for row in tqdm(reader):\n",
    "        paper_nid = int(row['paper_nid']) \n",
    "        paper_name = row['paper_name'].strip() \n",
    "        ntype = int(row['node_type']) \n",
    "        assert ntype == 0 \n",
    "        paper_label = int(row['paper_label'])\n",
    "        assert paper_label in [0, 1, 2, 3] \n",
    "        \n",
    "        assert nid_map[paper_nid][0] == 'paper'\n",
    "        assert paper_label_arr[nid_map[paper_nid][1]] == -1 \n",
    "        paper_label_arr[nid_map[paper_nid][1]] = paper_label\n",
    "        paper_train_mask[nid_map[paper_nid][1]] = True \n",
    "    \n",
    "paper_label_arr.shape, \\\n",
    "np.sum(paper_label_arr > -1), \\\n",
    "np.sum(paper_train_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2118it [00:00, 230615.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3025,), 3025)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.expanduser('~/dataset/HGB/raw/ACM/label.dat.test'), 'r', encoding='utf-8') as fp:\n",
    "    reader = csv.DictReader(fp, fieldnames=['paper_nid', 'paper_name', 'node_type', 'paper_label'], delimiter='\\t') \n",
    "    \n",
    "    for row in tqdm(reader):\n",
    "        paper_nid = int(row['paper_nid']) \n",
    "        paper_name = row['paper_name'].strip() \n",
    "        ntype = int(row['node_type']) \n",
    "        assert ntype == 0 \n",
    "        paper_label = int(row['paper_label'])\n",
    "        assert paper_label in [0, 1, 2, 3] \n",
    "        \n",
    "        assert nid_map[paper_nid][0] == 'paper'\n",
    "        assert paper_label_arr[nid_map[paper_nid][1]] == -1 \n",
    "        paper_label_arr[nid_map[paper_nid][1]] = paper_label\n",
    "    \n",
    "paper_label_arr.shape, \\\n",
    "np.sum(paper_label_arr > -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import torch \n",
    "\n",
    "PP_edge_index = torch.tensor(paper_paper_edge_index, dtype=torch.int64) \n",
    "PP_edge_index = torch.cat([PP_edge_index, torch.flip(PP_edge_index, dims=[0])], dim=-1)\n",
    "PP_edge_index = torch.unique(PP_edge_index, dim=-1) \n",
    "\n",
    "with open(os.path.expanduser(os.path.expanduser('~/dataset/HGB/processed/ACM_hg.dict.pkl')), 'wb') as fp:\n",
    "    pickle.dump(\n",
    "        dict(\n",
    "            node_feat_dict = dict(\n",
    "                author = torch.tensor(author_feat, dtype=torch.float32),  \n",
    "                paper = torch.tensor(paper_feat, dtype=torch.float32),  \n",
    "                subject = torch.tensor(subject_feat, dtype=torch.float32),  \n",
    "            ), \n",
    "            num_nodes_dict = dict(\n",
    "                author = len(author_feat), \n",
    "                paper = len(paper_feat), \n",
    "                subject = len(subject_feat), \n",
    "                term = len(term_feat_list), \n",
    "            ),\n",
    "            edge_index_dict = {\n",
    "                ('paper', 'PP', 'paper'): PP_edge_index,\n",
    "                ('paper', 'PA', 'author'): torch.tensor(paper_author_edge_index, dtype=torch.int64), \n",
    "                ('author', 'AP', 'paper'): torch.tensor(author_paper_edge_index, dtype=torch.int64), \n",
    "                ('paper', 'PT', 'term'): torch.tensor(paper_term_edge_index, dtype=torch.int64), \n",
    "                ('term', 'TP', 'paper'): torch.tensor(term_paper_edge_index, dtype=torch.int64), \n",
    "                ('paper', 'PS', 'subject'): torch.tensor(paper_subject_edge_index, dtype=torch.int64), \n",
    "                ('subject', 'SP', 'paper'): torch.tensor(subject_paper_edge_index, dtype=torch.int64), \n",
    "            },\n",
    "            paper_label = torch.tensor(paper_label_arr, dtype=torch.int64),  \n",
    "            paper_train_mask = torch.tensor(paper_train_mask, dtype=torch.bool),\n",
    "            paper_test_mask = torch.tensor(~paper_train_mask, dtype=torch.bool),\n",
    "        ), \n",
    "        fp, \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
