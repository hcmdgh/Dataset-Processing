{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os \n",
    "import torch \n",
    "from collections import Counter \n",
    "from tqdm import tqdm \n",
    "\n",
    "with open(os.path.expanduser(\"~/dataset/OAG/raw/PT-HGNN/graph_CS_20190919.dict.pkl\"), \"rb\") as fp:\n",
    "    graph_info = pickle.load(fp) \n",
    "    \n",
    "edge_list = graph_info['edge_list'] \n",
    "node_feature = graph_info['node_feature']\n",
    "node_forward = graph_info['node_forward'] \n",
    "times = graph_info['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546704"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_paper_nodes = len(node_feature[\"paper\"])\n",
    "\n",
    "num_paper_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:57<00:00,  9.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(546704), tensor(1.))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_year_vec = torch.zeros(num_paper_nodes, dtype=torch.int64)\n",
    "\n",
    "for etype in tqdm(graph_info['edge_list']['field']['paper']):\n",
    "    for field_id in graph_info['edge_list']['field']['paper'][etype]: \n",
    "        for paper_id in graph_info['edge_list']['field']['paper'][etype][field_id]: \n",
    "            paper_year = graph_info['edge_list']['field']['paper'][etype][field_id][paper_id] \n",
    "\n",
    "            if paper_year_vec[paper_id] == 0: \n",
    "                paper_year_vec[paper_id] = paper_year \n",
    "            else: \n",
    "                assert paper_year_vec[paper_id] == paper_year \n",
    "                \n",
    "(paper_year_vec > 0).sum(), (paper_year_vec > 0).float().mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1922, 1),\n",
       "  (1930, 1),\n",
       "  (1938, 1),\n",
       "  (1946, 1),\n",
       "  (1948, 1),\n",
       "  (1950, 1),\n",
       "  (1951, 2),\n",
       "  (1952, 3),\n",
       "  (1953, 1),\n",
       "  (1954, 10)],\n",
       " [(2011, 30523),\n",
       "  (2012, 33140),\n",
       "  (2013, 35382),\n",
       "  (2014, 36214),\n",
       "  (2015, 39314),\n",
       "  (2016, 38459),\n",
       "  (2017, 39072),\n",
       "  (2018, 34293),\n",
       "  (2019, 16308),\n",
       "  (2020, 255)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_result = sorted(Counter(paper_year_vec.tolist()).items()) \n",
    "\n",
    "counter_result[:10], counter_result[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([('venue', 'PV_Conference', 'paper'), ('venue', 'PV_Journal', 'paper'), ('venue', 'PV_Repository', 'paper'), ('venue', 'PV_Patent', 'paper'), ('paper', 'rev_PV_Conference', 'venue'), ('paper', 'rev_PV_Journal', 'venue'), ('paper', 'rev_PV_Repository', 'venue'), ('paper', 'rev_PV_Patent', 'venue'), ('paper', 'PP_cite', 'paper'), ('paper', 'rev_PP_cite', 'paper'), ('paper', 'rev_PF_in_L0', 'field'), ('paper', 'rev_PF_in_L3', 'field'), ('paper', 'rev_PF_in_L1', 'field'), ('paper', 'rev_PF_in_L2', 'field'), ('paper', 'rev_PF_in_L5', 'field'), ('paper', 'rev_PF_in_L4', 'field'), ('paper', 'AP_write_last', 'author'), ('paper', 'AP_write_other', 'author'), ('paper', 'AP_write_first', 'author'), ('field', 'FF_in', 'field'), ('field', 'rev_FF_in', 'field'), ('field', 'PF_in_L0', 'paper'), ('field', 'PF_in_L3', 'paper'), ('field', 'PF_in_L1', 'paper'), ('field', 'PF_in_L2', 'paper'), ('field', 'PF_in_L5', 'paper'), ('field', 'PF_in_L4', 'paper'), ('affiliation', 'in', 'author'), ('author', 'rev_in', 'affiliation'), ('author', 'rev_AP_write_last', 'paper'), ('author', 'rev_AP_write_other', 'paper'), ('author', 'rev_AP_write_first', 'paper')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_dict = dict() \n",
    "\n",
    "for src_ntype in tqdm(graph_info['edge_list']): \n",
    "    for dest_ntype in graph_info['edge_list'][src_ntype]:\n",
    "        for etype in graph_info['edge_list'][src_ntype][dest_ntype]:\n",
    "            edge_list = [] \n",
    "            \n",
    "            for src_nid in graph_info['edge_list'][src_ntype][dest_ntype][etype]: \n",
    "                for dest_nid in graph_info['edge_list'][src_ntype][dest_ntype][etype][src_nid]: \n",
    "                    edge_list.append((src_nid, dest_nid))\n",
    "\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.int64).T \n",
    "            \n",
    "            edge_index_dict[(src_ntype, etype, dest_ntype)] = edge_index \n",
    "\n",
    "edge_index_dict.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('venue', 'VP_Conference', 'paper'), ('venue', 'VP_Journal', 'paper'), ('venue', 'VP_Repository', 'paper'), ('venue', 'VP_Patent', 'paper'), ('paper', 'PV_Conference', 'venue'), ('paper', 'PV_Journal', 'venue'), ('paper', 'PV_Repository', 'venue'), ('paper', 'PV_Patent', 'venue'), ('paper', 'PP_cite', 'paper'), ('paper', 'PF_L0', 'field'), ('paper', 'PF_L3', 'field'), ('paper', 'PF_L1', 'field'), ('paper', 'PF_L2', 'field'), ('paper', 'PF_L5', 'field'), ('paper', 'PF_L4', 'field'), ('paper', 'PA_last', 'author'), ('paper', 'PA_other', 'author'), ('paper', 'PA_first', 'author'), ('field', 'FF_in', 'field'), ('field', 'FP_L0', 'paper'), ('field', 'FP_L3', 'paper'), ('field', 'FP_L1', 'paper'), ('field', 'FP_L2', 'paper'), ('field', 'FP_L5', 'paper'), ('field', 'FP_L4', 'paper'), ('institution', 'in', 'author'), ('author', 'in', 'institution'), ('author', 'AP_last', 'paper'), ('author', 'AP_other', 'paper'), ('author', 'AP_first', 'paper')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_edge_index_dict = dict() \n",
    "\n",
    "for (src_ntype, etype, dest_ntype), edge_index in edge_index_dict.items(): \n",
    "    if src_ntype == 'affiliation': \n",
    "        src_ntype = 'institution' \n",
    "    if dest_ntype == 'affiliation': \n",
    "        dest_ntype = 'institution'    \n",
    "    \n",
    "    if etype[:2].isupper(): \n",
    "        etype = etype[1] + etype[0] + etype[2:] \n",
    "    elif etype[:3] == 'rev': \n",
    "        etype = etype[4:]\n",
    "        \n",
    "    etype = etype.replace('_in_', '_')\n",
    "    etype = etype.replace('_write_', '_')\n",
    "        \n",
    "    _edge_index_dict[(src_ntype, etype, dest_ntype)] = edge_index \n",
    "    \n",
    "edge_index_dict = _edge_index_dict \n",
    "\n",
    "edge_index_dict.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('venue', 'VP_Conference', 'paper'): torch.Size([2, 298075]),\n",
       " ('venue', 'VP_Journal', 'paper'): torch.Size([2, 229104]),\n",
       " ('venue', 'VP_Repository', 'paper'): torch.Size([2, 19318]),\n",
       " ('venue', 'VP_Patent', 'paper'): torch.Size([2, 207]),\n",
       " ('paper', 'PV_Conference', 'venue'): torch.Size([2, 298075]),\n",
       " ('paper', 'PV_Journal', 'venue'): torch.Size([2, 229104]),\n",
       " ('paper', 'PV_Repository', 'venue'): torch.Size([2, 19318]),\n",
       " ('paper', 'PV_Patent', 'venue'): torch.Size([2, 207]),\n",
       " ('paper', 'PF_L0', 'field'): torch.Size([2, 546831]),\n",
       " ('paper', 'PF_L3', 'field'): torch.Size([2, 869729]),\n",
       " ('paper', 'PF_L1', 'field'): torch.Size([2, 1202487]),\n",
       " ('paper', 'PF_L2', 'field'): torch.Size([2, 2347239]),\n",
       " ('paper', 'PF_L5', 'field'): torch.Size([2, 203338]),\n",
       " ('paper', 'PF_L4', 'field'): torch.Size([2, 304912]),\n",
       " ('paper', 'PA_last', 'author'): torch.Size([2, 431027]),\n",
       " ('paper', 'PA_other', 'author'): torch.Size([2, 664266]),\n",
       " ('paper', 'PA_first', 'author'): torch.Size([2, 456903]),\n",
       " ('field', 'FF_in', 'field'): torch.Size([2, 262839]),\n",
       " ('field', 'FP_L0', 'paper'): torch.Size([2, 546831]),\n",
       " ('field', 'FP_L3', 'paper'): torch.Size([2, 869729]),\n",
       " ('field', 'FP_L1', 'paper'): torch.Size([2, 1202487]),\n",
       " ('field', 'FP_L2', 'paper'): torch.Size([2, 2347239]),\n",
       " ('field', 'FP_L5', 'paper'): torch.Size([2, 203338]),\n",
       " ('field', 'FP_L4', 'paper'): torch.Size([2, 304912]),\n",
       " ('author', 'AP_last', 'paper'): torch.Size([2, 431027]),\n",
       " ('author', 'AP_other', 'paper'): torch.Size([2, 664266]),\n",
       " ('author', 'AP_first', 'paper'): torch.Size([2, 456903]),\n",
       " ('institution', 'IA', 'author'): torch.Size([2, 614161]),\n",
       " ('author', 'AI', 'institution'): torch.Size([2, 614161]),\n",
       " ('paper', 'PP', 'paper'): torch.Size([2, 11729984])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_dict[('institution', 'IA', 'author')] = edge_index_dict.pop(('institution', 'in', 'author'))\n",
    "edge_index_dict[('author', 'AI', 'institution')] = edge_index_dict.pop(('author', 'in', 'institution'))\n",
    "\n",
    "PP_edge_index = edge_index_dict.pop(('paper', 'PP_cite', 'paper')) \n",
    "PP_edge_index = torch.cat([PP_edge_index, torch.flip(PP_edge_index, dims=[0])], dim=-1) \n",
    "PP_edge_index = torch.unique(PP_edge_index, dim=-1) \n",
    "edge_index_dict[('paper', 'PP', 'paper')] = PP_edge_index \n",
    "\n",
    "{ k: v.shape for k, v in edge_index_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_edge_index = torch.cat([\n",
    "    edge_index_dict[('paper', 'PV_Conference', 'venue')], \n",
    "    edge_index_dict[('paper', 'PV_Journal', 'venue')], \n",
    "    edge_index_dict[('paper', 'PV_Repository', 'venue')], \n",
    "    edge_index_dict[('paper', 'PV_Patent', 'venue')], \n",
    "], dim=-1)\n",
    "\n",
    "PV_edge_index = torch.unique(PV_edge_index, dim=-1) \n",
    "\n",
    "VP_edge_index = torch.flip(PV_edge_index, dims=[0]) \n",
    "\n",
    "edge_index_dict[('paper', 'PV', 'venue')] = PV_edge_index \n",
    "edge_index_dict[('venue', 'VP', 'paper')] = VP_edge_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_edge_index = torch.cat([\n",
    "    edge_index_dict[('paper', 'PF_L5', 'field')], \n",
    "    edge_index_dict[('paper', 'PF_L4', 'field')], \n",
    "    edge_index_dict[('paper', 'PF_L3', 'field')], \n",
    "    edge_index_dict[('paper', 'PF_L2', 'field')], \n",
    "], dim=-1)\n",
    "\n",
    "PF_edge_index = torch.unique(PF_edge_index, dim=-1) \n",
    "\n",
    "FP_edge_index = torch.flip(PF_edge_index, dims=[0]) \n",
    "\n",
    "edge_index_dict[('paper', 'PF', 'field')] = PF_edge_index \n",
    "edge_index_dict[('field', 'FP', 'paper')] = FP_edge_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('venue', 'VP_Conference', 'paper'): torch.Size([2, 298075]),\n",
       " ('venue', 'VP_Journal', 'paper'): torch.Size([2, 229104]),\n",
       " ('venue', 'VP_Repository', 'paper'): torch.Size([2, 19318]),\n",
       " ('venue', 'VP_Patent', 'paper'): torch.Size([2, 207]),\n",
       " ('paper', 'PV_Conference', 'venue'): torch.Size([2, 298075]),\n",
       " ('paper', 'PV_Journal', 'venue'): torch.Size([2, 229104]),\n",
       " ('paper', 'PV_Repository', 'venue'): torch.Size([2, 19318]),\n",
       " ('paper', 'PV_Patent', 'venue'): torch.Size([2, 207]),\n",
       " ('paper', 'PF_L0', 'field'): torch.Size([2, 546831]),\n",
       " ('paper', 'PF_L3', 'field'): torch.Size([2, 869729]),\n",
       " ('paper', 'PF_L1', 'field'): torch.Size([2, 1202487]),\n",
       " ('paper', 'PF_L2', 'field'): torch.Size([2, 2347239]),\n",
       " ('paper', 'PF_L5', 'field'): torch.Size([2, 203338]),\n",
       " ('paper', 'PF_L4', 'field'): torch.Size([2, 304912]),\n",
       " ('paper', 'PA_last', 'author'): torch.Size([2, 431027]),\n",
       " ('paper', 'PA_other', 'author'): torch.Size([2, 664266]),\n",
       " ('paper', 'PA_first', 'author'): torch.Size([2, 456903]),\n",
       " ('field', 'FF_in', 'field'): torch.Size([2, 262839]),\n",
       " ('field', 'FP_L0', 'paper'): torch.Size([2, 546831]),\n",
       " ('field', 'FP_L3', 'paper'): torch.Size([2, 869729]),\n",
       " ('field', 'FP_L1', 'paper'): torch.Size([2, 1202487]),\n",
       " ('field', 'FP_L2', 'paper'): torch.Size([2, 2347239]),\n",
       " ('field', 'FP_L5', 'paper'): torch.Size([2, 203338]),\n",
       " ('field', 'FP_L4', 'paper'): torch.Size([2, 304912]),\n",
       " ('author', 'AP_last', 'paper'): torch.Size([2, 431027]),\n",
       " ('author', 'AP_other', 'paper'): torch.Size([2, 664266]),\n",
       " ('author', 'AP_first', 'paper'): torch.Size([2, 456903]),\n",
       " ('institution', 'IA', 'author'): torch.Size([2, 614161]),\n",
       " ('author', 'AI', 'institution'): torch.Size([2, 614161]),\n",
       " ('paper', 'PP', 'paper'): torch.Size([2, 11729984]),\n",
       " ('paper', 'PV', 'venue'): torch.Size([2, 546704]),\n",
       " ('venue', 'VP', 'paper'): torch.Size([2, 546704]),\n",
       " ('paper', 'PF', 'field'): torch.Size([2, 3725218]),\n",
       " ('field', 'FP', 'paper'): torch.Size([2, 3725218]),\n",
       " ('paper', 'PA', 'author'): torch.Size([2, 1552196]),\n",
       " ('author', 'AP', 'paper'): torch.Size([2, 1552196])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA_edge_index = torch.cat([\n",
    "    edge_index_dict[('paper', 'PA_last', 'author')], \n",
    "    edge_index_dict[('paper', 'PA_other', 'author')], \n",
    "    edge_index_dict[('paper', 'PA_first', 'author')], \n",
    "], dim=-1)\n",
    "\n",
    "PA_edge_index = torch.unique(PA_edge_index, dim=-1) \n",
    "\n",
    "AP_edge_index = torch.flip(PA_edge_index, dims=[0]) \n",
    "\n",
    "edge_index_dict[('paper', 'PA', 'author')] = PA_edge_index \n",
    "edge_index_dict[('author', 'AP', 'paper')] = AP_edge_index \n",
    "\n",
    "{ k: v.shape for k, v in edge_index_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 511122,\n",
       " 'field': 45775,\n",
       " 'institution': 9090,\n",
       " 'paper': 546704,\n",
       " 'venue': 6946}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl \n",
    "\n",
    "hg = dgl.heterograph({k: tuple(v) for k, v in edge_index_dict.items()}) \n",
    "num_nodes_dict = { ntype: hg.num_nodes(ntype) for ntype in hg.ntypes } \n",
    "\n",
    "num_nodes_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([546704, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_feat_mat = torch.tensor(list(node_feature['paper']['emb']), dtype=torch.float32) \n",
    "\n",
    "paper_feat_mat.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.expanduser('~/dataset/OAG/OAG-CS/hg_full.dict.pkl'), 'wb') as fp: \n",
    "    pickle.dump(\n",
    "        dict(\n",
    "            edge_index_dict = edge_index_dict, \n",
    "            num_nodes_dict = num_nodes_dict, \n",
    "            paper_feat = paper_feat_mat, \n",
    "            paper_year = paper_year_vec, \n",
    "        ), \n",
    "        fp, \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
