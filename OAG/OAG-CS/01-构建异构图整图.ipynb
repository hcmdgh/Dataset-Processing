{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os \n",
    "import torch \n",
    "from collections import Counter \n",
    "from tqdm import tqdm \n",
    "\n",
    "with open(os.path.expanduser(\"~/dataset/OAG/raw/graph_CS.dict.pkl\"), \"rb\") as fp:\n",
    "    graph_info = pickle.load(fp) \n",
    "    \n",
    "edge_list = graph_info['edge_list'] \n",
    "node_feature = graph_info['node_feature']\n",
    "node_forward = graph_info['node_forward'] \n",
    "times = graph_info['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544244"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_paper_nodes = len(node_feature[\"paper\"])\n",
    "\n",
    "num_paper_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:56<00:00,  9.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(544244), tensor(1.))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_year_vec = torch.zeros(num_paper_nodes, dtype=torch.int64)\n",
    "\n",
    "for etype in tqdm(graph_info['edge_list']['field']['paper']):\n",
    "    for field_id in graph_info['edge_list']['field']['paper'][etype]: \n",
    "        for paper_id in graph_info['edge_list']['field']['paper'][etype][field_id]: \n",
    "            paper_year = graph_info['edge_list']['field']['paper'][etype][field_id][paper_id] \n",
    "\n",
    "            if paper_year_vec[paper_id] == 0: \n",
    "                paper_year_vec[paper_id] = paper_year \n",
    "            else: \n",
    "                assert paper_year_vec[paper_id] == paper_year \n",
    "                \n",
    "(paper_year_vec > 0).sum(), (paper_year_vec > 0).float().mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6265), tensor(0.2087), tensor(0.0716), tensor(0.0933))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_pretrain_mask = torch.zeros(num_paper_nodes, dtype=torch.bool)\n",
    "paper_train_mask = torch.zeros(num_paper_nodes, dtype=torch.bool)\n",
    "paper_val_mask = torch.zeros(num_paper_nodes, dtype=torch.bool)\n",
    "paper_test_mask = torch.zeros(num_paper_nodes, dtype=torch.bool)\n",
    "\n",
    "paper_pretrain_mask[paper_year_vec < 2014] = True \n",
    "paper_train_mask[(paper_year_vec >= 2014) & (paper_year_vec <= 2016)] = True \n",
    "paper_val_mask[paper_year_vec == 2017] = True \n",
    "paper_test_mask[paper_year_vec >= 2018] = True \n",
    "\n",
    "paper_pretrain_mask.float().mean(), \\\n",
    "    paper_train_mask.float().mean(), \\\n",
    "    paper_val_mask.float().mean(), \\\n",
    "    paper_test_mask.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1922, 1),\n",
       "  (1930, 1),\n",
       "  (1938, 1),\n",
       "  (1946, 1),\n",
       "  (1948, 1),\n",
       "  (1950, 1),\n",
       "  (1951, 2),\n",
       "  (1952, 3),\n",
       "  (1953, 1),\n",
       "  (1954, 10)],\n",
       " [(2011, 30429),\n",
       "  (2012, 33031),\n",
       "  (2013, 35273),\n",
       "  (2014, 36100),\n",
       "  (2015, 39158),\n",
       "  (2016, 38309),\n",
       "  (2017, 38942),\n",
       "  (2018, 34218),\n",
       "  (2019, 16281),\n",
       "  (2020, 254)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_result = sorted(Counter(paper_year_vec.tolist()).items()) \n",
    "\n",
    "counter_result[:10], counter_result[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([('venue', 'PV_Conference', 'paper'), ('venue', 'PV_Journal', 'paper'), ('venue', 'PV_Repository', 'paper'), ('venue', 'PV_Patent', 'paper'), ('paper', 'rev_PV_Conference', 'venue'), ('paper', 'rev_PV_Journal', 'venue'), ('paper', 'rev_PV_Repository', 'venue'), ('paper', 'rev_PV_Patent', 'venue'), ('paper', 'PP_cite', 'paper'), ('paper', 'rev_PP_cite', 'paper'), ('paper', 'rev_PF_in_L0', 'field'), ('paper', 'rev_PF_in_L3', 'field'), ('paper', 'rev_PF_in_L1', 'field'), ('paper', 'rev_PF_in_L2', 'field'), ('paper', 'rev_PF_in_L5', 'field'), ('paper', 'rev_PF_in_L4', 'field'), ('paper', 'AP_write_last', 'author'), ('paper', 'AP_write_other', 'author'), ('paper', 'AP_write_first', 'author'), ('field', 'FF_in', 'field'), ('field', 'rev_FF_in', 'field'), ('field', 'PF_in_L0', 'paper'), ('field', 'PF_in_L3', 'paper'), ('field', 'PF_in_L1', 'paper'), ('field', 'PF_in_L2', 'paper'), ('field', 'PF_in_L5', 'paper'), ('field', 'PF_in_L4', 'paper'), ('affiliation', 'in', 'author'), ('author', 'rev_in', 'affiliation'), ('author', 'rev_AP_write_last', 'paper'), ('author', 'rev_AP_write_other', 'paper'), ('author', 'rev_AP_write_first', 'paper')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_dict = dict() \n",
    "\n",
    "for src_ntype in tqdm(graph_info['edge_list']): \n",
    "    for dest_ntype in graph_info['edge_list'][src_ntype]:\n",
    "        for etype in graph_info['edge_list'][src_ntype][dest_ntype]:\n",
    "            edge_list = [] \n",
    "            \n",
    "            for src_nid in graph_info['edge_list'][src_ntype][dest_ntype][etype]: \n",
    "                for dest_nid in graph_info['edge_list'][src_ntype][dest_ntype][etype][src_nid]: \n",
    "                    edge_list.append((src_nid, dest_nid))\n",
    "\n",
    "            edge_index = torch.tensor(edge_list, dtype=torch.int64).T \n",
    "            \n",
    "            edge_index_dict[(src_ntype, etype, dest_ntype)] = edge_index \n",
    "\n",
    "edge_index_dict.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('venue', 'VP_Conference', 'paper'), ('venue', 'VP_Journal', 'paper'), ('venue', 'VP_Repository', 'paper'), ('venue', 'VP_Patent', 'paper'), ('paper', 'PV_Conference', 'venue'), ('paper', 'PV_Journal', 'venue'), ('paper', 'PV_Repository', 'venue'), ('paper', 'PV_Patent', 'venue'), ('paper', 'PP_cite', 'paper'), ('paper', 'PF_L0', 'field'), ('paper', 'PF_L3', 'field'), ('paper', 'PF_L1', 'field'), ('paper', 'PF_L2', 'field'), ('paper', 'PF_L5', 'field'), ('paper', 'PF_L4', 'field'), ('paper', 'PA_last', 'author'), ('paper', 'PA_other', 'author'), ('paper', 'PA_first', 'author'), ('field', 'FF_in', 'field'), ('field', 'FP_L0', 'paper'), ('field', 'FP_L3', 'paper'), ('field', 'FP_L1', 'paper'), ('field', 'FP_L2', 'paper'), ('field', 'FP_L5', 'paper'), ('field', 'FP_L4', 'paper'), ('institution', 'in', 'author'), ('author', 'in', 'institution'), ('author', 'AP_last', 'paper'), ('author', 'AP_other', 'paper'), ('author', 'AP_first', 'paper')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_edge_index_dict = dict() \n",
    "\n",
    "for (src_ntype, etype, dest_ntype), edge_index in edge_index_dict.items(): \n",
    "    if src_ntype == 'affiliation': \n",
    "        src_ntype = 'institution' \n",
    "    if dest_ntype == 'affiliation': \n",
    "        dest_ntype = 'institution'    \n",
    "    \n",
    "    if etype[:2].isupper(): \n",
    "        etype = etype[1] + etype[0] + etype[2:] \n",
    "    elif etype[:3] == 'rev': \n",
    "        etype = etype[4:]\n",
    "        \n",
    "    etype = etype.replace('_in_', '_')\n",
    "    etype = etype.replace('_write_', '_')\n",
    "        \n",
    "    _edge_index_dict[(src_ntype, etype, dest_ntype)] = edge_index \n",
    "    \n",
    "edge_index_dict = _edge_index_dict \n",
    "\n",
    "edge_index_dict.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('venue', 'VP_Conference', 'paper'): torch.Size([2, 296775]),\n",
       " ('venue', 'VP_Journal', 'paper'): torch.Size([2, 228062]),\n",
       " ('venue', 'VP_Repository', 'paper'): torch.Size([2, 19216]),\n",
       " ('venue', 'VP_Patent', 'paper'): torch.Size([2, 191]),\n",
       " ('paper', 'PV_Conference', 'venue'): torch.Size([2, 296775]),\n",
       " ('paper', 'PV_Journal', 'venue'): torch.Size([2, 228062]),\n",
       " ('paper', 'PV_Repository', 'venue'): torch.Size([2, 19216]),\n",
       " ('paper', 'PV_Patent', 'venue'): torch.Size([2, 191]),\n",
       " ('paper', 'PF_L0', 'field'): torch.Size([2, 544371]),\n",
       " ('paper', 'PF_L3', 'field'): torch.Size([2, 866423]),\n",
       " ('paper', 'PF_L1', 'field'): torch.Size([2, 1197205]),\n",
       " ('paper', 'PF_L2', 'field'): torch.Size([2, 2337525]),\n",
       " ('paper', 'PF_L5', 'field'): torch.Size([2, 202221]),\n",
       " ('paper', 'PF_L4', 'field'): torch.Size([2, 303541]),\n",
       " ('paper', 'PA_last', 'author'): torch.Size([2, 429392]),\n",
       " ('paper', 'PA_other', 'author'): torch.Size([2, 662167]),\n",
       " ('paper', 'PA_first', 'author'): torch.Size([2, 454913]),\n",
       " ('field', 'FF_in', 'field'): torch.Size([2, 262526]),\n",
       " ('field', 'FP_L0', 'paper'): torch.Size([2, 544371]),\n",
       " ('field', 'FP_L3', 'paper'): torch.Size([2, 866423]),\n",
       " ('field', 'FP_L1', 'paper'): torch.Size([2, 1197205]),\n",
       " ('field', 'FP_L2', 'paper'): torch.Size([2, 2337525]),\n",
       " ('field', 'FP_L5', 'paper'): torch.Size([2, 202221]),\n",
       " ('field', 'FP_L4', 'paper'): torch.Size([2, 303541]),\n",
       " ('author', 'AP_last', 'paper'): torch.Size([2, 429392]),\n",
       " ('author', 'AP_other', 'paper'): torch.Size([2, 662167]),\n",
       " ('author', 'AP_first', 'paper'): torch.Size([2, 454913]),\n",
       " ('institution', 'IA', 'author'): torch.Size([2, 612872]),\n",
       " ('author', 'AI', 'institution'): torch.Size([2, 612872]),\n",
       " ('paper', 'PP', 'paper'): torch.Size([2, 11577794])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_dict[('institution', 'IA', 'author')] = edge_index_dict.pop(('institution', 'in', 'author'))\n",
    "edge_index_dict[('author', 'AI', 'institution')] = edge_index_dict.pop(('author', 'in', 'institution'))\n",
    "\n",
    "PP_edge_index = edge_index_dict.pop(('paper', 'PP_cite', 'paper')) \n",
    "PP_edge_index = torch.cat([PP_edge_index, torch.flip(PP_edge_index, dims=[0])], dim=-1) \n",
    "PP_edge_index = torch.unique(PP_edge_index, dim=-1) \n",
    "edge_index_dict[('paper', 'PP', 'paper')] = PP_edge_index \n",
    "\n",
    "{ k: v.shape for k, v in edge_index_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 510189,\n",
       " 'field': 45717,\n",
       " 'institution': 9079,\n",
       " 'paper': 544244,\n",
       " 'venue': 6934}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl \n",
    "\n",
    "hg = dgl.heterograph({k: tuple(v) for k, v in edge_index_dict.items()}) \n",
    "num_nodes_dict = { ntype: hg.num_nodes(ntype) for ntype in hg.ntypes } \n",
    "\n",
    "num_nodes_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([544244, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_feat_mat = torch.tensor(list(node_feature['paper']['emb']), dtype=torch.float32) \n",
    "\n",
    "paper_feat_mat.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4190), 3505)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PV_edge_index = edge_index_dict[('paper', 'PV_Journal', 'venue')] \n",
    "\n",
    "paper_venue_label_vec = torch.full(fill_value=-1, size=[num_paper_nodes], dtype=torch.int64)\n",
    "\n",
    "venue_remap: dict[int, int] = dict() \n",
    "\n",
    "for paper_nid, venue_nid in zip(*PV_edge_index.tolist()):\n",
    "    if venue_nid not in venue_remap: \n",
    "        venue_remap[venue_nid] = len(venue_remap) \n",
    "\n",
    "    label_id = venue_remap[venue_nid] \n",
    "    \n",
    "    if paper_venue_label_vec[paper_nid] == -1: \n",
    "        paper_venue_label_vec[paper_nid] = label_id \n",
    "    else:\n",
    "        assert paper_venue_label_vec[paper_nid] == label_id \n",
    "\n",
    "(paper_venue_label_vec > -1).float().mean(), \\\n",
    "    int(torch.max(paper_venue_label_vec)) + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([544244, 275]), tensor(0.0080))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PF_edge_index = edge_index_dict[('paper', 'PF_L1', 'field')] \n",
    "\n",
    "field_remap: dict[int, int] = dict() \n",
    "\n",
    "for paper_nid, field_nid in zip(*PF_edge_index.tolist()):\n",
    "    if field_nid not in field_remap: \n",
    "        field_remap[field_nid] = len(field_remap) \n",
    "        \n",
    "paper_field_label_mat = torch.zeros([num_paper_nodes, len(field_remap)], dtype=torch.bool)\n",
    "        \n",
    "for paper_nid, field_nid in zip(*PF_edge_index.tolist()):\n",
    "    label_id = field_remap[field_nid] \n",
    "    \n",
    "    paper_field_label_mat[paper_nid, label_id] = True \n",
    "\n",
    "paper_field_label_mat.shape, \\\n",
    "    paper_field_label_mat.float().mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/gh/dataset/OAG/OAG-CS-Venue/hg_full.dict.pkl', 'wb') as fp: \n",
    "    pickle.dump(\n",
    "        dict(\n",
    "            edge_index_dict = edge_index_dict, \n",
    "            num_nodes_dict = num_nodes_dict, \n",
    "            paper_feat = paper_feat_mat, \n",
    "            paper_year = paper_year_vec, \n",
    "            paper_pretrain_mask = paper_pretrain_mask, \n",
    "            paper_train_mask = paper_train_mask, \n",
    "            paper_val_mask = paper_val_mask, \n",
    "            paper_test_mask = paper_test_mask, \n",
    "            paper_venue_label = paper_venue_label_vec, \n",
    "            paper_field_label = paper_field_label_mat, \n",
    "        ), \n",
    "        fp, \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
