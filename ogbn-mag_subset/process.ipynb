{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroGraph:\n",
       "{'num_nodes_dict': {'author': 1134649,\n",
       "                    'institution': 8740,\n",
       "                    'paper': 736389,\n",
       "                    'field': 59965},\n",
       " 'total_num_nodes': 1939743,\n",
       " 'num_edges_dict': {('author', 'ai', 'institution'): 1043998,\n",
       "                    ('author', 'ap', 'paper'): 7145660,\n",
       "                    ('paper', 'pp_cites', 'paper'): 5416271,\n",
       "                    ('paper', 'pf', 'field'): 7505078,\n",
       "                    ('institution', 'ia', 'author'): 1043998,\n",
       "                    ('paper', 'pa', 'author'): 7145660,\n",
       "                    ('paper', 'pp_cited', 'paper'): 5416271,\n",
       "                    ('field', 'fp', 'paper'): 7505078},\n",
       " 'total_num_edges': 42222014,\n",
       " 'device': 'cpu'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jojo_graph \n",
    "from jojo_graph.imports import * \n",
    "\n",
    "dataset = jojo_graph.hetero_graph_dataset.OGB.OgbnMag()\n",
    "graph = dataset.graph \n",
    "feat = dataset.feat \n",
    "label = dataset.label \n",
    "train_mask = dataset.train_mask\n",
    "val_mask = dataset.val_mask\n",
    "test_mask = dataset.test_mask\n",
    "\n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 30902), (134, 30671), (300, 27542), (258, 24804), (283, 24463)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(label.tolist())\n",
    "\n",
    "label_subset = counter.most_common(5)\n",
    "label_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138382, 0.1879197000498378)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_subset_cnt = sum(x[1] for x in label_subset)\n",
    "label_subset_cnt, label_subset_cnt / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 134, 258, 283, 300}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_subset = { x[0] for x in label_subset }\n",
    "label_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138382"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_id_subset = { i for i, lb in enumerate(label.tolist()) if lb in label_subset }\n",
    "len(paper_id_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ogbn_mag_subset(hg: jojo_graph.HeteroGraph,\n",
    "                             paper_id_subset: set[int]) -> jojo_graph.HeteroGraph:\n",
    "    PA_edge_index = hg.edge_index_dict[('paper', 'pa', 'author')].tolist()\n",
    "    PF_edge_index = hg.edge_index_dict[('paper', 'pf', 'field')].tolist()\n",
    "    PP_edge_index = hg.edge_index_dict[('paper', 'pp_cites', 'paper')].tolist()\n",
    "    AI_edge_index = hg.edge_index_dict[('author', 'ai', 'institution')].tolist()\n",
    "    \n",
    "    paper_nid_to_oid_map: list[int] = sorted(paper_id_subset)\n",
    "\n",
    "    paper_oid_to_nid_map: dict[int, int] = { \n",
    "        oid: nid \n",
    "        for nid, oid in enumerate(paper_nid_to_oid_map) \n",
    "    } \n",
    "    \n",
    "    author_oid_to_nid_map: dict[int, int] = dict() \n",
    "    paper_nid_to_author_nid_map: dict[int, set[int]] = defaultdict(set)\n",
    "\n",
    "    for paper_oid, author_oid in zip(*PA_edge_index):\n",
    "        if paper_oid in paper_oid_to_nid_map:\n",
    "            paper_nid = paper_oid_to_nid_map[paper_oid]\n",
    "            \n",
    "            if author_oid not in author_oid_to_nid_map:\n",
    "                author_oid_to_nid_map[author_oid] = len(author_oid_to_nid_map)\n",
    "            \n",
    "            author_nid = author_oid_to_nid_map[author_oid]\n",
    "            paper_nid_to_author_nid_map[paper_nid].add(author_nid)\n",
    "\n",
    "    field_oid_to_nid_map: dict[int, int] = dict() \n",
    "    paper_nid_to_field_nid_map: dict[int, set[int]] = defaultdict(set)\n",
    "\n",
    "    for paper_oid, field_oid in zip(*PF_edge_index):\n",
    "        if paper_oid in paper_oid_to_nid_map:\n",
    "            paper_nid = paper_oid_to_nid_map[paper_oid]\n",
    "            \n",
    "            if field_oid not in field_oid_to_nid_map:\n",
    "                field_oid_to_nid_map[field_oid] = len(field_oid_to_nid_map)\n",
    "            \n",
    "            field_nid = field_oid_to_nid_map[field_oid]\n",
    "            paper_nid_to_field_nid_map[paper_nid].add(field_nid)\n",
    "    \n",
    "    institution_oid_to_nid_map: dict[int, int] = dict() \n",
    "    author_nid_to_institution_nid_map: dict[int, set[int]] = defaultdict(set) \n",
    "\n",
    "    for author_oid, institution_oid in zip(*AI_edge_index):\n",
    "        if author_oid in author_oid_to_nid_map:\n",
    "            author_nid = author_oid_to_nid_map[author_oid]\n",
    "            \n",
    "            if institution_oid not in institution_oid_to_nid_map:\n",
    "                institution_oid_to_nid_map[institution_oid] = len(institution_oid_to_nid_map)\n",
    "                \n",
    "            institution_nid = institution_oid_to_nid_map[institution_oid]\n",
    "            author_nid_to_institution_nid_map[author_nid].add(institution_nid) \n",
    "            \n",
    "    new_PA_edge_index: tuple[list[int], list[int]] = [], [] \n",
    "    for paper_nid in paper_nid_to_author_nid_map:\n",
    "        for author_nid in paper_nid_to_author_nid_map[paper_nid]:\n",
    "            new_PA_edge_index[0].append(paper_nid)\n",
    "            new_PA_edge_index[1].append(author_nid)\n",
    "\n",
    "    new_PF_edge_index: tuple[list[int], list[int]] = [], [] \n",
    "    for paper_nid in paper_nid_to_field_nid_map:\n",
    "        for field_nid in paper_nid_to_field_nid_map[paper_nid]:\n",
    "            new_PF_edge_index[0].append(paper_nid)\n",
    "            new_PF_edge_index[1].append(field_nid)\n",
    "            \n",
    "    new_AI_edge_index: tuple[list[int], list[int]] = [], [] \n",
    "    for author_nid in author_nid_to_institution_nid_map:\n",
    "        for institution_nid in author_nid_to_institution_nid_map[author_nid]:\n",
    "            new_AI_edge_index[0].append(author_nid)\n",
    "            new_AI_edge_index[1].append(institution_nid)\n",
    "            \n",
    "    new_PP_edge_index: tuple[list[int], list[int]] = [], []\n",
    "    for paper_oid_1, paper_oid_2 in zip(*PP_edge_index): \n",
    "        if paper_oid_1 in paper_oid_to_nid_map and paper_oid_2 in paper_oid_to_nid_map: \n",
    "            paper_nid_1 = paper_oid_to_nid_map[paper_oid_1]\n",
    "            paper_nid_2 = paper_oid_to_nid_map[paper_oid_2]\n",
    "            new_PP_edge_index[0].append(paper_nid_1)\n",
    "            new_PP_edge_index[1].append(paper_nid_2)\n",
    "            \n",
    "    new_edge_index_dict: dict[EdgeType, IntTensor] = {\n",
    "        ('author', 'ai', 'institution'): torch.tensor(new_AI_edge_index), \n",
    "        ('author', 'ap', 'paper'): torch.tensor(new_PA_edge_index[::-1]), \n",
    "        ('paper', 'pp_cites', 'paper'): torch.tensor(new_PP_edge_index), \n",
    "        ('paper', 'pf', 'field'): torch.tensor(new_PF_edge_index), \n",
    "        ('institution', 'ia', 'author'): torch.tensor(new_AI_edge_index[::-1]), \n",
    "        ('paper', 'pa', 'author'): torch.tensor(new_PA_edge_index), \n",
    "        ('paper', 'pp_cited', 'paper'): torch.tensor(new_PP_edge_index[::-1]), \n",
    "        ('field', 'fp', 'paper'): torch.tensor(new_PF_edge_index[::-1]), \n",
    "    }\n",
    "    \n",
    "    new_num_nodes_dict: dict[NodeType, int] = {\n",
    "        'paper': len(paper_oid_to_nid_map),\n",
    "        'author': len(author_oid_to_nid_map),\n",
    "        'field': len(field_oid_to_nid_map),\n",
    "        'institution': len(institution_oid_to_nid_map),\n",
    "    }\n",
    "    \n",
    "    return jojo_graph.HeteroGraph(\n",
    "        edge_index_dict = new_edge_index_dict, \n",
    "        num_nodes_dict = new_num_nodes_dict, \n",
    "        device = hg.device,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroGraph:\n",
       "{'num_nodes_dict': {'paper': 138382,\n",
       "                    'author': 260402,\n",
       "                    'field': 21680,\n",
       "                    'institution': 4936},\n",
       " 'total_num_nodes': 425400,\n",
       " 'num_edges_dict': {('author', 'ai', 'institution'): 279401,\n",
       "                    ('author', 'ap', 'paper'): 928352,\n",
       "                    ('paper', 'pp_cites', 'paper'): 976341,\n",
       "                    ('paper', 'pf', 'field'): 1458089,\n",
       "                    ('institution', 'ia', 'author'): 279401,\n",
       "                    ('paper', 'pa', 'author'): 928352,\n",
       "                    ('paper', 'pp_cited', 'paper'): 976341,\n",
       "                    ('field', 'fp', 'paper'): 1458089},\n",
       " 'total_num_edges': 7284366,\n",
       " 'device': 'cpu'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hg = generate_ogbn_mag_subset(graph, paper_id_subset)\n",
    "new_hg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138382\n",
      "tensor(122828) tensor(0.8876)\n",
      "tensor(8806) tensor(0.0636)\n",
      "tensor(6748) tensor(0.0488)\n"
     ]
    }
   ],
   "source": [
    "paper_oid_list = sorted(paper_id_subset)\n",
    "\n",
    "new_paper_feat = feat[paper_oid_list]\n",
    "\n",
    "new_label = label[paper_oid_list]\n",
    "label_oid_to_nid_map: dict[int, int] = dict() \n",
    "for label_oid in new_label.tolist():\n",
    "    if label_oid not in label_oid_to_nid_map:\n",
    "        label_oid_to_nid_map[label_oid] = len(label_oid_to_nid_map)\n",
    "new_label = torch.tensor([ label_oid_to_nid_map[label_oid] for label_oid in new_label.tolist() ], dtype=torch.int64)\n",
    "\n",
    "new_train_mask = train_mask[paper_oid_list]\n",
    "new_val_mask = val_mask[paper_oid_list]\n",
    "new_test_mask = test_mask[paper_oid_list]\n",
    "\n",
    "print(len(new_label))\n",
    "print(new_train_mask.sum(), new_train_mask.sum() / len(new_label))\n",
    "print(new_val_mask.sum(), new_val_mask.sum() / len(new_label))\n",
    "print(new_test_mask.sum(), new_test_mask.sum() / len(new_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 28600, 3: 27449, 2: 22771, 4: 22689, 1: 21319})\n",
      "Counter({1: 3447, 3: 2071, 0: 1480, 2: 1126, 4: 682})\n",
      "Counter({1: 2776, 4: 1433, 3: 1382, 0: 591, 2: 566})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(new_label[new_train_mask].tolist()))\n",
    "print(Counter(new_label[new_val_mask].tolist()))\n",
    "print(Counter(new_label[new_test_mask].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_info = dict(\n",
    "    edge_index_dict = new_hg.edge_index_dict,\n",
    "    num_nodes_dict = new_hg.num_nodes_dict, \n",
    "    feat_dict = dict(\n",
    "        paper = new_paper_feat, \n",
    "        author = torch.rand(new_hg.num_nodes_dict['author'], new_paper_feat.shape[-1], dtype=torch.float32), \n",
    "        field = torch.rand(new_hg.num_nodes_dict['field'], new_paper_feat.shape[-1], dtype=torch.float32), \n",
    "        institution = torch.rand(new_hg.num_nodes_dict['institution'], new_paper_feat.shape[-1], dtype=torch.float32), \n",
    "    ), \n",
    "    label = new_label, \n",
    "    train_mask = new_train_mask,   \n",
    "    val_mask = new_val_mask,   \n",
    "    test_mask = new_test_mask,   \n",
    ")\n",
    "\n",
    "with open('/home/genghao/dataset/hetero_graph/OGB/ogbn-mag/processed/ogbn-mag_field_top5.dict.pkl', 'wb') as fp:\n",
    "    pickle.dump(graph_info, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89b7a1d2e721a5682d780d5ad9c7563cf3f1029f957bcc9ca02f4d8de7838a7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
